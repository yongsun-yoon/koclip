{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9b1a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from tqdm.auto import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from transformers import AutoTokenizer, AutoModel, CLIPModel, CLIPProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce4f9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_model(clip_model_name_or_path, kobert_model_name_or_path, device):\n",
    "    clip = CLIPModel.from_pretrained(clip_model_name_or_path)\n",
    "    clip_processor = CLIPProcessor.from_pretrained(clip_model_name_or_path)\n",
    "\n",
    "    kobert = AutoModel.from_pretrained(kobert_model_name_or_path)\n",
    "    kobert_tokenizer = AutoTokenizer.from_pretrained(kobert_model_name_or_path)\n",
    "\n",
    "    kobert.pooler.dense.weight.data = kobert.pooler.dense.weight[:clip.projection_dim].data\n",
    "    kobert.pooler.dense.bias.data = kobert.pooler.dense.bias[:clip.projection_dim].data\n",
    "\n",
    "    clip.text_model = kobert\n",
    "    clip_processor.tokenizer = kobert_tokenizer\n",
    "\n",
    "    _ = clip.requires_grad_(False).eval().to(device)\n",
    "    return clip, clip_processor\n",
    "\n",
    "def prepare_prompts():\n",
    "    prompts = []\n",
    "    for c in CLASSES:\n",
    "        c_prompts = []\n",
    "        for t in TEMPLATES:\n",
    "            c_prompts.append(t.format(c))\n",
    "        prompts.append(c_prompts)\n",
    "    return prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11296781",
   "metadata": {
    "code_folding": [
     0,
     8
    ]
   },
   "outputs": [],
   "source": [
    "TEMPLATES = [\n",
    "    '이것은 {}이다.',\n",
    "    '{}를 찍은 사진.',\n",
    "    '{}를 찍은 흐릿한 사진.',\n",
    "    '{}가 담겨 있는 이미지.',\n",
    "    '제목: {}'\n",
    "]\n",
    "\n",
    "CLASSES = [\n",
    "    '사과', # apple\n",
    "    '관상용 물고기', # aquarium_fish\n",
    "    '아기', # baby\n",
    "    '곰', # bear\n",
    "    '비버', # beaver\n",
    "    '침대', # bed\n",
    "    '벌', # bee\n",
    "    '딱정벌레', # beetle\n",
    "    '자전거', # bicycle\n",
    "    '병', # bottle\n",
    "    '그릇', # bowl\n",
    "    '남자 아이', # boy\n",
    "    '다리', # bridge\n",
    "    '버스', # bus\n",
    "    '나비', # butterfly\n",
    "    '낙타', # camel\n",
    "    '깡통', # can\n",
    "    '성', # castle\n",
    "    '애벌레', # caterpillar\n",
    "    '소', # cattle\n",
    "    '의자', # chair\n",
    "    '침팬지', # chimpanzee\n",
    "    '시계', # clock\n",
    "    '구름', # cloud\n",
    "    '바퀴벌레', # cockroach\n",
    "    '소파', # couch\n",
    "    '게', # crab\n",
    "    '악어', # crocodile\n",
    "    '컵', # cup\n",
    "    '공룡', # dinosaur\n",
    "    '돌고래', # dolphin\n",
    "    '코끼리', # elephant\n",
    "    '넙치', # flatfish\n",
    "    '숲', # forest\n",
    "    '여우', # fox\n",
    "    '여자 아이', # girl\n",
    "    '햄스터', # hamster\n",
    "    '집', # house\n",
    "    '캥거루', # kangaroo\n",
    "    '키보드', # keyboard\n",
    "    '램프', # lamp\n",
    "    '잔디 깎는 기계', # lawn mower\n",
    "    '표범', # leopard\n",
    "    '사자', # lion\n",
    "    '도마뱀', # lizard\n",
    "    '바닷가재', # lobster\n",
    "    '남자', # man\n",
    "    '단풍나무', # maple tree\n",
    "    '오토바이', # motocycle\n",
    "    '산', # mountain\n",
    "    '쥐', # mouse\n",
    "    '버섯', # mushroom\n",
    "    '오크 나무', # oak tree\n",
    "    '오렌지', # orange\n",
    "    '난초', # orchid\n",
    "    '수달', # otter\n",
    "    '야자나무', # palm tree\n",
    "    '배', # pear\n",
    "    '트럭', # pickup truck\n",
    "    '소나무', # pine tree\n",
    "    '들판', # plane\n",
    "    '접시', # plate\n",
    "    '강아지', # poppy\n",
    "    '호저', # porcupine\n",
    "    '주머니쥐', # possum\n",
    "    '토끼', # rabbit\n",
    "    '너구리', # raccoon\n",
    "    '가오리', # ray\n",
    "    '길', # road\n",
    "    '로켓', # rocket\n",
    "    '장미', # rose\n",
    "    '바다', # sea\n",
    "    '물개', # seal\n",
    "    '상어', # shark\n",
    "    '땃쥐', # shrew\n",
    "    '스컹크', # skunk\n",
    "    '고층 건물', # skyscraper\n",
    "    '달팽이', # snail\n",
    "    '뱀', # snake\n",
    "    '거미', # spider\n",
    "    '다람쥐', # squirrel\n",
    "    '전차', # streetcar\n",
    "    '해바라기', # sunflower\n",
    "    '피망', # sweet pepper\n",
    "    '탁자', # table\n",
    "    '탱크', # tank\n",
    "    '전화기', # telephone\n",
    "    '텔레비전', # television\n",
    "    '호랑이', # tiger\n",
    "    '트랙터', # tractor\n",
    "    '기차', # train\n",
    "    '송어', # trout\n",
    "    '튤립', # tulip\n",
    "    '거북이', # turtle\n",
    "    '옷장', # wardrobe\n",
    "    '고래', # whale\n",
    "    '버드나무', # willow tree\n",
    "    '늑대', # wolf\n",
    "    '여자', # woman\n",
    "    '지렁이', # worm\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2200922",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip, clip_processor = prepare_model('openai/clip-vit-base-patch32', '../ckpt', 'cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb53a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "text.pop('token_type_ids')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f1ffaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af69dc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0205ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_embeddings = get_text_embeddings(clip, clip_processor, CLASSES, TEMPLATES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2a9ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = torchvision.datasets.CIFAR100('../data/cifar100', train=False, download=True)\n",
    "datas = list(datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26a9dacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4085a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(10, 32) * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be66acdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2025, -0.0815,  0.1343, -0.0433,  0.2385, -0.1463, -0.1612, -0.0822,\n",
       "         -0.0147,  0.0390,  0.0575, -0.0082,  0.1963, -0.1190, -0.0764, -0.0230,\n",
       "         -0.3746, -0.2803, -0.2629,  0.0335,  0.1221, -0.2356,  0.0475, -0.3802,\n",
       "         -0.0549,  0.1243, -0.0118,  0.0284,  0.1609, -0.1235, -0.2513,  0.3566],\n",
       "        [ 0.1154, -0.4262, -0.1690,  0.0320,  0.0062, -0.0073,  0.3820, -0.0378,\n",
       "          0.1474,  0.0862,  0.1588,  0.3089, -0.0606,  0.0586,  0.1454,  0.0033,\n",
       "          0.1367, -0.0786, -0.0263,  0.2364, -0.0300, -0.0906, -0.0460,  0.1971,\n",
       "         -0.0589, -0.1663,  0.1893, -0.3718, -0.0533, -0.0147,  0.0754, -0.3234],\n",
       "        [-0.1234, -0.1378,  0.0642, -0.0557,  0.0313,  0.1041, -0.1868, -0.1637,\n",
       "         -0.1646,  0.0277, -0.0440, -0.2785,  0.1929,  0.1443,  0.1977,  0.0491,\n",
       "         -0.1454, -0.1318,  0.0874, -0.2764,  0.1210, -0.1717,  0.1125, -0.0702,\n",
       "          0.1240, -0.5936,  0.2213,  0.0614,  0.1017, -0.1369,  0.2097,  0.0201],\n",
       "        [ 0.0945, -0.0887,  0.3827, -0.2675,  0.0037, -0.0127, -0.2698, -0.0802,\n",
       "         -0.2823, -0.0069,  0.1286,  0.1379,  0.1387, -0.0078, -0.0366, -0.2080,\n",
       "          0.0707,  0.2325,  0.1962,  0.2158, -0.1285,  0.0661, -0.1979, -0.1087,\n",
       "          0.0274,  0.1134, -0.0609, -0.0614,  0.1716, -0.2632, -0.3066, -0.2770],\n",
       "        [ 0.3001,  0.1192, -0.2865, -0.2756,  0.2945,  0.3517,  0.0432,  0.1717,\n",
       "          0.0148, -0.1653, -0.2453,  0.2336, -0.0448,  0.3396,  0.0040,  0.0189,\n",
       "          0.2870,  0.1651, -0.1686,  0.0015,  0.0448, -0.0760,  0.0182, -0.1876,\n",
       "          0.0923,  0.0169,  0.0811,  0.0311,  0.0175, -0.0817, -0.0905, -0.1515],\n",
       "        [-0.0617,  0.1699, -0.0922,  0.3191,  0.3902, -0.0537,  0.0278, -0.3057,\n",
       "          0.2454,  0.2544,  0.1587, -0.3097, -0.0580, -0.0287,  0.0035,  0.1188,\n",
       "         -0.1423,  0.0549, -0.2392, -0.0625, -0.0602, -0.1036, -0.3012,  0.2601,\n",
       "         -0.0593, -0.1017, -0.0135, -0.0716,  0.0919, -0.2075, -0.1199,  0.0342],\n",
       "        [-0.1454,  0.0039,  0.1173, -0.1143,  0.0607, -0.2969,  0.1670,  0.2162,\n",
       "         -0.1494, -0.0134, -0.3221,  0.0545, -0.2338, -0.0456,  0.0804,  0.0672,\n",
       "          0.1765,  0.0861,  0.2312,  0.2123,  0.2833,  0.1004,  0.4695,  0.0053,\n",
       "          0.0333, -0.1062, -0.1627, -0.0209, -0.1658,  0.1445, -0.1000,  0.2075],\n",
       "        [-0.3309, -0.0066, -0.1262,  0.0044, -0.2438,  0.1160, -0.2963, -0.2899,\n",
       "         -0.1230, -0.0504, -0.3745,  0.0137, -0.0437, -0.0073, -0.1231, -0.0425,\n",
       "          0.2181,  0.3171,  0.1255, -0.1545, -0.0860, -0.1866,  0.0935, -0.0301,\n",
       "         -0.0679,  0.0217,  0.2744, -0.1698,  0.1080,  0.1534,  0.2469, -0.0889],\n",
       "        [-0.1003,  0.1228, -0.1557, -0.2374,  0.0037, -0.1793,  0.1053, -0.2981,\n",
       "         -0.1028,  0.2508,  0.4222,  0.0052,  0.1701, -0.0118, -0.1139,  0.0089,\n",
       "          0.0284, -0.2277, -0.1311, -0.0561,  0.0471,  0.3533,  0.1790, -0.1221,\n",
       "         -0.2966,  0.0096, -0.0656, -0.0916, -0.0553,  0.0671,  0.3126, -0.1234],\n",
       "        [ 0.0118,  0.1647,  0.0808, -0.2937,  0.0783,  0.1015,  0.0308, -0.1668,\n",
       "          0.0043,  0.0072, -0.2009, -0.0405,  0.0251, -0.1073,  0.0657,  0.2133,\n",
       "          0.0096, -0.1668, -0.0087, -0.2786, -0.4121, -0.1863, -0.0945, -0.0926,\n",
       "          0.2205,  0.1725,  0.2296, -0.3452, -0.1050, -0.1283, -0.3028, -0.1835]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a / a.norm(dim=1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51c9d911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2025, -0.0815,  0.1343, -0.0433,  0.2385, -0.1463, -0.1612, -0.0822,\n",
       "         -0.0147,  0.0390,  0.0575, -0.0082,  0.1963, -0.1190, -0.0764, -0.0230,\n",
       "         -0.3746, -0.2803, -0.2629,  0.0335,  0.1221, -0.2356,  0.0475, -0.3802,\n",
       "         -0.0549,  0.1243, -0.0118,  0.0284,  0.1609, -0.1235, -0.2513,  0.3566],\n",
       "        [ 0.1154, -0.4262, -0.1690,  0.0320,  0.0062, -0.0073,  0.3820, -0.0378,\n",
       "          0.1474,  0.0862,  0.1588,  0.3089, -0.0606,  0.0586,  0.1454,  0.0033,\n",
       "          0.1367, -0.0786, -0.0263,  0.2364, -0.0300, -0.0906, -0.0460,  0.1971,\n",
       "         -0.0589, -0.1663,  0.1893, -0.3718, -0.0533, -0.0147,  0.0754, -0.3234],\n",
       "        [-0.1234, -0.1378,  0.0642, -0.0557,  0.0313,  0.1041, -0.1868, -0.1637,\n",
       "         -0.1646,  0.0277, -0.0440, -0.2785,  0.1929,  0.1443,  0.1977,  0.0491,\n",
       "         -0.1454, -0.1318,  0.0874, -0.2764,  0.1210, -0.1717,  0.1125, -0.0702,\n",
       "          0.1240, -0.5936,  0.2213,  0.0614,  0.1017, -0.1369,  0.2097,  0.0201],\n",
       "        [ 0.0945, -0.0887,  0.3827, -0.2675,  0.0037, -0.0127, -0.2698, -0.0802,\n",
       "         -0.2823, -0.0069,  0.1286,  0.1379,  0.1387, -0.0078, -0.0366, -0.2080,\n",
       "          0.0707,  0.2325,  0.1962,  0.2158, -0.1285,  0.0661, -0.1979, -0.1087,\n",
       "          0.0274,  0.1134, -0.0609, -0.0614,  0.1716, -0.2632, -0.3066, -0.2770],\n",
       "        [ 0.3001,  0.1192, -0.2865, -0.2756,  0.2945,  0.3517,  0.0432,  0.1717,\n",
       "          0.0148, -0.1653, -0.2453,  0.2336, -0.0448,  0.3396,  0.0040,  0.0189,\n",
       "          0.2870,  0.1651, -0.1686,  0.0015,  0.0448, -0.0760,  0.0182, -0.1876,\n",
       "          0.0923,  0.0169,  0.0811,  0.0311,  0.0175, -0.0817, -0.0905, -0.1515],\n",
       "        [-0.0617,  0.1699, -0.0922,  0.3191,  0.3902, -0.0537,  0.0278, -0.3057,\n",
       "          0.2454,  0.2544,  0.1587, -0.3097, -0.0580, -0.0287,  0.0035,  0.1188,\n",
       "         -0.1423,  0.0549, -0.2392, -0.0625, -0.0602, -0.1036, -0.3012,  0.2601,\n",
       "         -0.0593, -0.1017, -0.0135, -0.0716,  0.0919, -0.2075, -0.1199,  0.0342],\n",
       "        [-0.1454,  0.0039,  0.1173, -0.1143,  0.0607, -0.2969,  0.1670,  0.2162,\n",
       "         -0.1494, -0.0134, -0.3221,  0.0545, -0.2338, -0.0456,  0.0804,  0.0672,\n",
       "          0.1765,  0.0861,  0.2312,  0.2123,  0.2833,  0.1004,  0.4695,  0.0053,\n",
       "          0.0333, -0.1062, -0.1627, -0.0209, -0.1658,  0.1445, -0.1000,  0.2075],\n",
       "        [-0.3309, -0.0066, -0.1262,  0.0044, -0.2438,  0.1160, -0.2963, -0.2899,\n",
       "         -0.1230, -0.0504, -0.3745,  0.0137, -0.0437, -0.0073, -0.1231, -0.0425,\n",
       "          0.2181,  0.3171,  0.1255, -0.1545, -0.0860, -0.1866,  0.0935, -0.0301,\n",
       "         -0.0679,  0.0217,  0.2744, -0.1698,  0.1080,  0.1534,  0.2469, -0.0889],\n",
       "        [-0.1003,  0.1228, -0.1557, -0.2374,  0.0037, -0.1793,  0.1053, -0.2981,\n",
       "         -0.1028,  0.2508,  0.4222,  0.0052,  0.1701, -0.0118, -0.1139,  0.0089,\n",
       "          0.0284, -0.2277, -0.1311, -0.0561,  0.0471,  0.3533,  0.1790, -0.1221,\n",
       "         -0.2966,  0.0096, -0.0656, -0.0916, -0.0553,  0.0671,  0.3126, -0.1234],\n",
       "        [ 0.0118,  0.1647,  0.0808, -0.2937,  0.0783,  0.1015,  0.0308, -0.1668,\n",
       "          0.0043,  0.0072, -0.2009, -0.0405,  0.0251, -0.1073,  0.0657,  0.2133,\n",
       "          0.0096, -0.1668, -0.0087, -0.2786, -0.4121, -0.1863, -0.0945, -0.0926,\n",
       "          0.2205,  0.1725,  0.2296, -0.3452, -0.1050, -0.1283, -0.3028, -0.1835]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.normalize(a, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1027d526",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = datas[:10]\n",
    "batch_images, batch_labels = zip(*batch)\n",
    "batch_images, batch_labels = list(batch_images), list(batch_labels)\n",
    "inputs = clip_processor(images=batch_images, return_tensors=\"pt\", padding=True).to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86ca573",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4cc9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = clip.get_image_features(**inputs)\n",
    "emb = F.normalize(emb, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e032b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb @ text_embeddings.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e909cb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = torch.matmul(emb, text_embeddings.T).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2e6c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(outputs, torch.tensor(batch_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fbd534",
   "metadata": {},
   "outputs": [],
   "source": [
    "kobert_tokenizer = AutoTokenizer.from_pretrained(ckpt)\n",
    "kobert = AutoModel.from_pretrained(ckpt)\n",
    "\n",
    "clip = CLIPModel.from_pretrained('openai/clip-vit-base-patch32')\n",
    "clip_processor = CLIPProcessor.from_pretrained('openai/clip-vit-base-patch32')\n",
    "\n",
    "kobert.pooler.dense.weight.data = kobert.pooler.dense.weight[:512].data\n",
    "kobert.pooler.dense.bias.data = kobert.pooler.dense.bias[:512].data\n",
    "\n",
    "clip.text_model = kobert\n",
    "clip_processor.tokenizer = kobert_tokenizer\n",
    "\n",
    "_ = clip.requires_grad_(False).eval().to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659633a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc03143",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d7033b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33075845",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdc6162",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(glob('../data/test_images/*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a96cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpaths = sorted(glob('../data/test_images/*.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0711c0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = json.load(open('../data/labels.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380b31a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = lambda x: f'이 사진은 {x}이다.'\n",
    "prompt = lambda x: f'이것은 {x}이다.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b138d3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = [\n",
    "    '비행기',\n",
    "    '새',\n",
    "    '자동차',\n",
    "    '고양이',\n",
    "    '사슴',\n",
    "    '개',\n",
    "    '말',\n",
    "    '원숭이',\n",
    "    '배',\n",
    "    '트럭'\n",
    "]\n",
    "\n",
    "text = [prompt(c) for c in class_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73d6492",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for i in tqdm(range(0, len(images), 32)):\n",
    "    batch_images = images[i:i+32]\n",
    "    inputs = clip_processor(text=text, images=batch_images, return_tensors=\"pt\", padding=True).to('cuda:0')\n",
    "    outputs = clip(input_ids=inputs.input_ids, attention_mask=inputs.attention_mask, pixel_values=inputs.pixel_values)\n",
    "    logits = outputs.logits_per_image\n",
    "    preds += logits.argmax(dim=1).cpu().tolist()\n",
    "preds = np.array(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6f4de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "(labels == preds).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f77f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "(labels == preds).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb6425e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
